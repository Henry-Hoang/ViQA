#!/bin/bash
#SBATCH --output="a.out.%j.%N.out"
#SBATCH --mem=128g
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=16     
#SBATCH --partition=gpuA100x4
#SBATCH --time=24:00:00
#SBATCH --account=bbmp-delta-gpu
#SBATCH --job-name=trans
#SBATCH --gpus-per-node=4
#SBATCH --gpus-per-task=4
#SBATCH --gpu-bind=verbose,per_task:1

  
module purge 
 
module load anaconda3_gpu
cd /u/huypn168/QATask
srun python3 -m torch.distributed.launch -m tools.translate_eng --gpus 4